{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import re\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import threading\n",
    "import sys\n",
    "\n",
    "class FOMC (object):\n",
    "    '''\n",
    "    A convenient class for extracting meeting minutes from the FOMC website\n",
    "    Example Usage:  \n",
    "        fomc = FOMC()\n",
    "        df = fomc.get_statements()\n",
    "        fomc.pickle(\"./df_minutes.pickle\")\n",
    "    '''\n",
    "\n",
    "    def __init__(self, base_url='https://www.federalreserve.gov', \n",
    "                 calendar_url='https://www.federalreserve.gov/monetarypolicy/fomccalendars.htm',\n",
    "                 historical_date = 2011,\n",
    "                 verbose = True,\n",
    "                 max_threads = 10):\n",
    "\n",
    "        self.base_url = base_url\n",
    "        self.calendar_url = calendar_url\n",
    "        self.df = None\n",
    "        self.links = None\n",
    "        self.dates = None\n",
    "        self.articles = None\n",
    "        self.verbose = verbose\n",
    "        self.HISTORICAL_DATE = historical_date\n",
    "        self.MAX_THREADS = max_threads\n",
    "    \n",
    "\n",
    "    def _get_links(self, from_year):\n",
    "        '''\n",
    "        private function that sets all the links for the FOMC meetings from the giving from_year\n",
    "        to the current most recent year\n",
    "        '''\n",
    "        if self.verbose:\n",
    "            print(\"Getting links...\")\n",
    "        self.links = []\n",
    "        fomc_meetings_socket = urlopen(self.calendar_url)\n",
    "        soup = BeautifulSoup(fomc_meetings_socket, 'html.parser')\n",
    "\n",
    "        statements = soup.find_all('a', href=re.compile('^/newsevents/pressreleases/monetary\\d{8}a.htm'))\n",
    "        self.links = [statement.attrs['href'] for statement in statements] \n",
    "\n",
    "        if from_year <= self.HISTORICAL_DATE:        \n",
    "            for year in range(from_year, self.HISTORICAL_DATE + 1):\n",
    "                fomc_yearly_url = self.base_url + '/monetarypolicy/fomchistorical' + str(year) + '.htm'\n",
    "                fomc_yearly_socket = urlopen(fomc_yearly_url)\n",
    "                soup_yearly = BeautifulSoup(fomc_yearly_socket, 'html.parser')\n",
    "                statements_historical = soup_yearly.findAll('a', text = 'Statement')\n",
    "                for statement_historical in statements_historical:\n",
    "                    self.links.append(statement_historical.attrs['href'])\n",
    "\n",
    "\n",
    "    def _date_from_link(self, link):\n",
    "        date = re.findall('[0-9]{8}', link)[0]\n",
    "        if date[4] == '0':\n",
    "            date = \"{}/{}/{}\".format(date[:4], date[5:6], date[6:])\n",
    "        else:\n",
    "            date = \"{}/{}/{}\".format(date[:4], date[4:6], date[6:])\n",
    "        return date\n",
    "\n",
    "\n",
    "    def _add_article(self, link, index=None):\n",
    "        '''\n",
    "        adds the related article for 1 link into the instance variable\n",
    "        index is the index in the article to add to. Due to concurrent\n",
    "        prcessing, we need to make sure the articles are stored in the\n",
    "        right order\n",
    "        '''\n",
    "        if self.verbose:\n",
    "            sys.stdout.write(\".\")\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        # date of the article content\n",
    "        self.dates.append(self._date_from_link(link))\n",
    "        statement_socket = urlopen(self.base_url + link)\n",
    "        statement = BeautifulSoup(statement_socket, 'html.parser')\n",
    "        paragraphs = statement.findAll('p')\n",
    "        self.articles[index]= \"\\n\\n\".join([paragraph.get_text().strip() for paragraph in paragraphs])\n",
    "\n",
    "\n",
    "    def _get_articles_multi_threaded(self):\n",
    "        '''\n",
    "        gets all articles using multi-threading\n",
    "        '''\n",
    "        if self.verbose:\n",
    "            print(\"Getting articles - Multi-threaded...\")\n",
    "\n",
    "        self.dates, self.articles = [], ['']*len(self.links)\n",
    "        jobs = []\n",
    "        # initiate and start threads:\n",
    "        index = 0\n",
    "        while index < len(self.links):\n",
    "            if len(jobs) < self.MAX_THREADS:\n",
    "                t = threading.Thread(target=self._add_article, args=(self.links[index],index,))\n",
    "                jobs.append(t)\n",
    "                t.start()\n",
    "                index += 1\n",
    "            else:    # wait for threads to complete and join them back into the main thread\n",
    "                t = jobs.pop(0)\n",
    "                t.join()\n",
    "        for t in jobs:\n",
    "            t.join()\n",
    "\n",
    "        for row in range(len(self.articles)):\n",
    "            self.articles[row] = self.articles[row].strip()\n",
    "\n",
    "\n",
    "    def get_statements(self, from_year=1994):\n",
    "        '''\n",
    "        Returns a Pandas DataFrame of meeting minutes with the date as the index\n",
    "        uses a date range of from_year to the most current\n",
    "        Input from_year is ignored if it is within the last 5 years as this is meant for \n",
    "        parsing much older years\n",
    "        '''\n",
    "        self._get_links(from_year)\n",
    "        print(\"There are\", len(self.links), 'statements')\n",
    "        self._get_articles_multi_threaded()\n",
    "\n",
    "        self.df = pd.DataFrame(self.articles, index = pd.to_datetime(self.dates)).sort_index()\n",
    "        self.df.columns = ['statements']\n",
    "        return self.df\n",
    "\n",
    "\n",
    "    def pick_df(self, filename=\"../data/minutes.pickle\"):\n",
    "        if filename:\n",
    "            if self.verbose:\n",
    "                print(\"Writing to\", filename)        \n",
    "            with open(filename, \"wb\") as output_file:\n",
    "                    pickle.dump(self.df, output_file)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #Example Usage\n",
    "\n",
    "    fomc = FOMC()\n",
    "    df = fomc.get_statements()\n",
    "    file = open('FOMC.pickle', 'wb')\n",
    "    pickle.dump(fomc, file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pymongo.results.InsertOneResult object at 0x0000027BA12E2208>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
